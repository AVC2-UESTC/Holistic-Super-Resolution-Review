# Transformer-based Methods  
Model | Description | Publication | Year
:-:|:-:|:-:|:-:
[IPT](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Pre-Trained_Image_Processing_Transformer_CVPR_2021_paper.pdf)|pre-trained model|CVPR|2021
[SwinIR](https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.pdf)|based on the Swin Transformer|ICCVW|2021
[CAT](https://arxiv.org/pdf/2211.13654.pdf)|rectangle transformer|NIPS|2022
[ESRT](https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Lu_Transformer_for_Single_Image_Super-Resolution_CVPRW_2022_paper.pdf)|Lightweight Transformer|CVPR|2022
[ELAN](https://arxiv.org/pdf/2203.06697.pdf)|shift convolution, group-wise self-attention|ECCV|2022
[LBNet](https://arxiv.org/pdf/2204.13286.pdf)|Lightweight Bimodal Network|IJCAI|2022
[HAT](https://arxiv.org/pdf/2205.04437.pdf)|Hybrid Attention Transformer|CVPR|2023
[EQSR](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Deep_Arbitrary-Scale_Image_Super-Resolution_via_Scale-Equivariance_Pursuit_CVPR_2023_paper.pdf)|Arbitrary-Scale|CVPR|2023
[CiaoSR](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_CiaoSR_Continuous_Implicit_Attention-in-Attention_Network_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.pdf)|Arbitrary-Scale|CVPR|2023
[NGram](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Compression-Aware_Video_Super-Resolution_CVPR_2023_paper.pdf)|modification of window|CVPR|2023
[Omni-SR](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Omni_Aggregation_Networks_for_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf)|spatial and channel attention|CVPR|2023
[CLIT](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Cascaded_Local_Implicit_Transformer_for_Arbitrary-Scale_Super-Resolution_CVPR_2023_paper.pdf)|Local Implicit Transformer|CVPR|2023